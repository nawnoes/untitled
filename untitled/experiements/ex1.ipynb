{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='2,3'\n",
    "import sys\n",
    "sys.path.append('/home/dev/untitled/')\n",
    "sys.path.append('/home/dev/untitled/untitled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-09 00:34:58.802845: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-09 00:34:58.803001: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-09 00:34:58.803196: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-09 00:35:00.126816: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/opt/conda/envs/jax_env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "from untitled.dataset import get_datasets\n",
    "import hparam\n",
    "\n",
    "import checkpointing as checkpointing\n",
    "from absl import app\n",
    "from typing import Sequence\n",
    "import optax\n",
    "import numpy as np\n",
    "from flax.linen import partitioning as nn_partitioning\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "from layers import DecoderOnlyTransformer\n",
    "import hparam\n",
    "from dataset import get_datasets, preprocess_dataset\n",
    "import utils\n",
    "# import temperature_sampler # for predict loop, to be added later\n",
    "import checkpointing\n",
    "\n",
    "import jax.numpy as jnp\n",
    "from jax import random\n",
    "from jax.experimental.pjit import pjit\n",
    "from jax.sharding import PartitionSpec as P\n",
    "from jax.sharding import Mesh\n",
    "\n",
    "from jax.experimental.compilation_cache import compilation_cache as cc\n",
    "\n",
    "from log import log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E1108 19:03:46.594042441   46035 server_chttp2.cc:40]        {\"created\":\"@1699437826.594014988\",\"description\":\"Only 1 addresses added out of total 2 resolved\",\"file\":\"external/com_github_grpc_grpc/src/core/ext/transport/chttp2/server/chttp2_server.cc\",\"file_line\":404,\"referenced_errors\":[{\"created\":\"@1699437826.594012801\",\"description\":\"Address family not supported by protocol\",\"errno\":97,\"file\":\"external/com_github_grpc_grpc/src/core/lib/iomgr/socket_utils_common_posix.cc\",\"file_line\":420,\"os_error\":\"Address family not supported by protocol\",\"syscall\":\"socket\",\"target_address\":\"[::1]:27100\"}]}\n"
     ]
    }
   ],
   "source": [
    "# jax.distributed.shutdown()\n",
    "# jax.distributed.initialize(coordinator_address='localhost:27100', num_processes=1, process_id=0, local_device_ids=\"9\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "devices:[cuda(id=0), cuda(id=1)]\n",
      "local_devices:[cuda(id=0), cuda(id=1)]\n"
     ]
    }
   ],
   "source": [
    "print(f'devices:{jax.devices()}')\n",
    "print(f'local_devices:{jax.local_devices()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '/home/dev/untitled/untitled/config/mini.yml', 'run_name=test_config']\n",
      "{'run_name': 'test_config'}\n",
      "Creating checkpoint manager\n",
      "Checkpoint manager created\n",
      "Devices: [cuda(id=0), cuda(id=1)] (num_deivces: 2)\n",
      "Decided on mesh: [[[cuda(id=0)]\n",
      "  [cuda(id=1)]]]\n"
     ]
    }
   ],
   "source": [
    "init_rng, next_rng = random.split(random.PRNGKey(0), 2)\n",
    "\n",
    "hparam.initialize(['','/home/dev/untitled/untitled/config/mini.yml', 'run_name=test_config'])\n",
    "\n",
    "# Tensorboard summary writer\n",
    "writer = SummaryWriter(hparam.config.tensorboard_dir)\n",
    "\n",
    "# orbax에서 checkpoint manager를 초기화\n",
    "checkpoint_manager = checkpointing.create_orbax_checkpoint_manager(\n",
    "        hparam.config.checkpoint_dir,\n",
    "        hparam.config.enable_checkpointing,\n",
    "        hparam.config.async_checkpointing\n",
    "    )\n",
    "\n",
    "devices_array = utils.create_device_mesh(hparam.config, None)\n",
    "mesh = Mesh(devices_array, hparam.config.mesh_axes)\n",
    "data_pspec = P(*hparam.config.data_sharding)\n",
    "\n",
    "optimizer = optax.adam(\n",
    "        utils.create_learning_rate_schedule(\n",
    "          learning_rate=hparam.config.learning_rate, warmup_steps=hparam.config.warmup_steps\n",
    "        ),\n",
    "        b1 = hparam.config.adam_b1,\n",
    "        b2 = hparam.config.adam_b2,\n",
    "        eps = hparam.config.adam_eps,\n",
    "        eps_root = hparam.config.adam_eps_root,  \n",
    "    )\n",
    "\n",
    "model = DecoderOnlyTransformer(hparam.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dev/untitled/untitled/utils.py:76: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "  assert (parallelism_vals.count(-1) == 1,\n",
      "/home/dev/untitled/untitled/utils.py:76: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "  assert (parallelism_vals.count(-1) == 1,\n",
      "/home/dev/untitled/untitled/utils.py:76: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "  assert (parallelism_vals.count(-1) == 1,\n",
      "/home/dev/untitled/untitled/utils.py:76: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "  assert (parallelism_vals.count(-1) == 1,\n",
      "/home/dev/untitled/untitled/utils.py:76: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "  assert (parallelism_vals.count(-1) == 1,\n",
      "/home/dev/untitled/untitled/utils.py:76: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "  assert (parallelism_vals.count(-1) == 1,\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "combine_biases() takes 0 positional arguments but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/dev/untitled/untitled/experiements/ex1.ipynb Cell 6\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f746f72636832222c2273657474696e6773223a7b22686f7374223a227373683a2f2f7562756e7475406563322d332d33362d36312d36382e61702d6e6f727468656173742d322e636f6d707574652e616d617a6f6e6177732e636f6d227d7d@ssh-remote%2Bgcp-lgair-lang-2022-3/home/dev/untitled/untitled/experiements/ex1.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# State\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f746f72636832222c2273657474696e6773223a7b22686f7374223a227373683a2f2f7562756e7475406563322d332d33362d36312d36382e61702d6e6f727468656173742d322e636f6d707574652e616d617a6f6e6177732e636f6d227d7d@ssh-remote%2Bgcp-lgair-lang-2022-3/home/dev/untitled/untitled/experiements/ex1.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m state, state_mesh_annotations \u001b[39m=\u001b[39m utils\u001b[39m.\u001b[39;49msetup_initial_state(model, optimizer, hparam\u001b[39m.\u001b[39;49mconfig, init_rng, mesh, checkpoint_manager)\n",
      "File \u001b[0;32m/home/dev/untitled/untitled/utils.py:149\u001b[0m, in \u001b[0;36msetup_initial_state\u001b[0;34m(model, optimizer, config, rng, mesh, checkpoint_manager)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msetup_initial_state\u001b[39m(model, optimizer, config, rng, mesh, checkpoint_manager):\n\u001b[1;32m    148\u001b[0m     init_train_state_partial \u001b[39m=\u001b[39m functools\u001b[39m.\u001b[39mpartial(init_train_state, model, optimizer, config)\n\u001b[0;32m--> 149\u001b[0m     abstract_state \u001b[39m=\u001b[39m jax\u001b[39m.\u001b[39;49meval_shape(init_train_state_partial, rng)\n\u001b[1;32m    150\u001b[0m     state_logical_annotations \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mget_partition_spec(abstract_state)\n\u001b[1;32m    151\u001b[0m     unboxed_abstract_state \u001b[39m=\u001b[39m unbox_logicaly_partitioned_trainstate(abstract_state)\n",
      "    \u001b[0;31m[... skipping hidden 8 frame]\u001b[0m\n",
      "File \u001b[0;32m/home/dev/untitled/untitled/utils.py:135\u001b[0m, in \u001b[0;36minit_train_state\u001b[0;34m(model, optimizer, config, key)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minit_train_state\u001b[39m(model, optimizer, config, key):\n\u001b[1;32m    134\u001b[0m     input_shape \u001b[39m=\u001b[39m (\u001b[39mlen\u001b[39m(jax\u001b[39m.\u001b[39mdevices()) \u001b[39m*\u001b[39m config\u001b[39m.\u001b[39mper_device_batch_size, config\u001b[39m.\u001b[39mmax_target_length)\n\u001b[0;32m--> 135\u001b[0m     model_variables \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49minit(\n\u001b[1;32m    136\u001b[0m         {\u001b[39m'\u001b[39;49m\u001b[39mparams\u001b[39;49m\u001b[39m'\u001b[39;49m:key, \u001b[39m'\u001b[39;49m\u001b[39mdroupout\u001b[39;49m\u001b[39m'\u001b[39;49m: key},\n\u001b[1;32m    137\u001b[0m         jnp\u001b[39m.\u001b[39;49mones(input_shape),\n\u001b[1;32m    138\u001b[0m         jnp\u001b[39m.\u001b[39;49mones(input_shape)\n\u001b[1;32m    139\u001b[0m     )\n\u001b[1;32m    140\u001b[0m     state \u001b[39m=\u001b[39m train_state\u001b[39m.\u001b[39mTrainState\u001b[39m.\u001b[39mcreate(\n\u001b[1;32m    141\u001b[0m         apply_fn\u001b[39m=\u001b[39mmodel\u001b[39m.\u001b[39mapply,\n\u001b[1;32m    142\u001b[0m         params\u001b[39m=\u001b[39mmodel_variables[\u001b[39m'\u001b[39m\u001b[39mparams\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m    143\u001b[0m         tx\u001b[39m=\u001b[39moptimizer\n\u001b[1;32m    144\u001b[0m     )\n\u001b[1;32m    145\u001b[0m     \u001b[39mreturn\u001b[39;00m state\n",
      "    \u001b[0;31m[... skipping hidden 9 frame]\u001b[0m\n",
      "File \u001b[0;32m/home/dev/untitled/untitled/layers.py:650\u001b[0m, in \u001b[0;36mDecoderOnlyTransformer.__call__\u001b[0;34m(self, decoder_input_tokens, decoder_target_tokens, decoder_segment_ids, decoder_positions, enable_dropout, decode, max_decode_length)\u001b[0m\n\u001b[1;32m    643\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    644\u001b[0m     decoder_mask \u001b[39m=\u001b[39m make_decoder_mask(\n\u001b[1;32m    645\u001b[0m         decoder_target_tokens\u001b[39m=\u001b[39mdecoder_target_tokens,\n\u001b[1;32m    646\u001b[0m         dtype\u001b[39m=\u001b[39mconfig\u001b[39m.\u001b[39mdtype,\n\u001b[1;32m    647\u001b[0m         decoder_segment_ids\u001b[39m=\u001b[39mdecoder_segment_ids\n\u001b[1;32m    648\u001b[0m     )\n\u001b[0;32m--> 650\u001b[0m logits \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdecoder(\n\u001b[1;32m    651\u001b[0m     decoder_input_tokens\u001b[39m=\u001b[39;49mdecoder_input_tokens,\n\u001b[1;32m    652\u001b[0m     decoder_positions\u001b[39m=\u001b[39;49mdecoder_positions,\n\u001b[1;32m    653\u001b[0m     decoder_mask\u001b[39m=\u001b[39;49mdecoder_mask,\n\u001b[1;32m    654\u001b[0m     deterministic\u001b[39m=\u001b[39;49m\u001b[39mnot\u001b[39;49;00m enable_dropout,\n\u001b[1;32m    655\u001b[0m     decode\u001b[39m=\u001b[39;49mdecode,\n\u001b[1;32m    656\u001b[0m     max_decode_length\u001b[39m=\u001b[39;49mmax_decode_length\n\u001b[1;32m    657\u001b[0m )\n\u001b[1;32m    659\u001b[0m \u001b[39mreturn\u001b[39;00m logits\n",
      "    \u001b[0;31m[... skipping hidden 2 frame]\u001b[0m\n",
      "File \u001b[0;32m/home/dev/untitled/untitled/layers.py:573\u001b[0m, in \u001b[0;36mDecoder.__call__\u001b[0;34m(self, decoder_input_tokens, decoder_positions, decoder_mask, deterministic, decode, max_decode_length)\u001b[0m\n\u001b[1;32m    569\u001b[0m     params_spec \u001b[39m=\u001b[39m (\n\u001b[1;32m    570\u001b[0m         config\u001b[39m.\u001b[39mparam_scan_axis \u001b[39mif\u001b[39;00m initializing \u001b[39melse\u001b[39;00m nn_partitioning\u001b[39m.\u001b[39mScanIn(config\u001b[39m.\u001b[39mparam_scan_axis)\n\u001b[1;32m    571\u001b[0m     )\n\u001b[1;32m    572\u001b[0m     cache_spec \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m--> 573\u001b[0m     y, _ \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39;49mscan(\n\u001b[1;32m    574\u001b[0m         BlockLayer,\n\u001b[1;32m    575\u001b[0m         variable_axes\u001b[39m=\u001b[39;49m{\n\u001b[1;32m    576\u001b[0m             \u001b[39m'\u001b[39;49m\u001b[39mparams\u001b[39;49m\u001b[39m'\u001b[39;49m: params_spec,\n\u001b[1;32m    577\u001b[0m             \u001b[39m'\u001b[39;49m\u001b[39mcache\u001b[39;49m\u001b[39m'\u001b[39;49m: cache_spec,\n\u001b[1;32m    578\u001b[0m             \u001b[39m'\u001b[39;49m\u001b[39mintermediates\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39m0\u001b[39;49m\n\u001b[1;32m    579\u001b[0m         },\n\u001b[1;32m    580\u001b[0m         split_rngs\u001b[39m=\u001b[39;49m{\n\u001b[1;32m    581\u001b[0m             \u001b[39m'\u001b[39;49m\u001b[39mparams\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    582\u001b[0m             \u001b[39m'\u001b[39;49m\u001b[39mdropout\u001b[39;49m\u001b[39m'\u001b[39;49m: config\u001b[39m.\u001b[39;49menable_dropout\n\u001b[1;32m    583\u001b[0m         },\n\u001b[1;32m    584\u001b[0m         in_axes\u001b[39m=\u001b[39;49m(nn\u001b[39m.\u001b[39;49mbroadcast, nn\u001b[39m.\u001b[39;49mbroadcast, nn\u001b[39m.\u001b[39;49mbroadcast, nn\u001b[39m.\u001b[39;49mbroadcast),\n\u001b[1;32m    585\u001b[0m         length\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mnum_decoder_layers,\n\u001b[1;32m    586\u001b[0m         metadata_params\u001b[39m=\u001b[39;49m{\n\u001b[1;32m    587\u001b[0m             nn\u001b[39m.\u001b[39;49mPARTITION_NAME: \u001b[39m'\u001b[39;49m\u001b[39mlayers\u001b[39;49m\u001b[39m'\u001b[39;49m\n\u001b[1;32m    588\u001b[0m         }\n\u001b[1;32m    589\u001b[0m     )(\n\u001b[1;32m    590\u001b[0m         config\u001b[39m=\u001b[39;49mconfig, name\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mdecoder\u001b[39;49m\u001b[39m'\u001b[39;49m\n\u001b[1;32m    591\u001b[0m         )(\n\u001b[1;32m    592\u001b[0m             y, decoder_mask,\n\u001b[1;32m    593\u001b[0m             deterministic, decode, max_decode_length\n\u001b[1;32m    594\u001b[0m         )\n\u001b[1;32m    596\u001b[0m y \u001b[39m=\u001b[39m LayerNorm(dtype\u001b[39m=\u001b[39mconfig\u001b[39m.\u001b[39mdtype, name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mdecoder_norm\u001b[39m\u001b[39m'\u001b[39m, kernel_axes\u001b[39m=\u001b[39m(\u001b[39m'\u001b[39m\u001b[39membed\u001b[39m\u001b[39m'\u001b[39m,))(y)\n\u001b[1;32m    597\u001b[0m y \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mDropout(\n\u001b[1;32m    598\u001b[0m     rate\u001b[39m=\u001b[39mconfig\u001b[39m.\u001b[39mdropout_rate,\n\u001b[1;32m    599\u001b[0m     broadcast_dims\u001b[39m=\u001b[39m(\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m,)\n\u001b[1;32m    600\u001b[0m )(y, deterministic\u001b[39m=\u001b[39mdeterministic)\n",
      "    \u001b[0;31m[... skipping hidden 3 frame]\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/envs/jax_env/lib/python3.10/site-packages/flax/core/axes_scan.py:150\u001b[0m, in \u001b[0;36mscan.<locals>.scan_fn\u001b[0;34m(broadcast_in, init, *args)\u001b[0m\n\u001b[1;32m    146\u001b[0m f_flat, out_tree \u001b[39m=\u001b[39m jax\u001b[39m.\u001b[39mapi_util\u001b[39m.\u001b[39mflatten_fun_nokwargs(\n\u001b[1;32m    147\u001b[0m     lu\u001b[39m.\u001b[39mwrap_init(broadcast_body), in_tree\n\u001b[1;32m    148\u001b[0m )\n\u001b[1;32m    149\u001b[0m in_pvals \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mmap\u001b[39m(pe\u001b[39m.\u001b[39mPartialVal\u001b[39m.\u001b[39munknown, in_avals))\n\u001b[0;32m--> 150\u001b[0m _, out_pvals, _ \u001b[39m=\u001b[39m pe\u001b[39m.\u001b[39;49mtrace_to_jaxpr_nounits(f_flat, in_pvals)\n\u001b[1;32m    152\u001b[0m out_flat \u001b[39m=\u001b[39m []\n\u001b[1;32m    153\u001b[0m \u001b[39mfor\u001b[39;00m pv, const \u001b[39min\u001b[39;00m out_pvals:\n",
      "    \u001b[0;31m[... skipping hidden 3 frame]\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/envs/jax_env/lib/python3.10/site-packages/flax/core/axes_scan.py:122\u001b[0m, in \u001b[0;36mscan.<locals>.scan_fn.<locals>.body_fn\u001b[0;34m(c, xs, init_mode)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbody_fn\u001b[39m(c, xs, init_mode\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m    118\u001b[0m   \u001b[39m# inject constants\u001b[39;00m\n\u001b[1;32m    119\u001b[0m   xs \u001b[39m=\u001b[39m jax\u001b[39m.\u001b[39mtree_util\u001b[39m.\u001b[39mtree_map(\n\u001b[1;32m    120\u001b[0m       \u001b[39mlambda\u001b[39;00m ax, arg, x: (arg \u001b[39mif\u001b[39;00m ax \u001b[39mis\u001b[39;00m broadcast \u001b[39melse\u001b[39;00m x), in_axes, args, xs\n\u001b[1;32m    121\u001b[0m   )\n\u001b[0;32m--> 122\u001b[0m   broadcast_out, c, ys \u001b[39m=\u001b[39m fn(broadcast_in, c, \u001b[39m*\u001b[39;49mxs)\n\u001b[1;32m    124\u001b[0m   \u001b[39mif\u001b[39;00m init_mode:\n\u001b[1;32m    125\u001b[0m     ys \u001b[39m=\u001b[39m jax\u001b[39m.\u001b[39mtree_util\u001b[39m.\u001b[39mtree_map(\n\u001b[1;32m    126\u001b[0m         \u001b[39mlambda\u001b[39;00m ax, y: (y \u001b[39mif\u001b[39;00m ax \u001b[39mis\u001b[39;00m broadcast \u001b[39melse\u001b[39;00m ()), out_axes, ys\n\u001b[1;32m    127\u001b[0m     )\n",
      "    \u001b[0;31m[... skipping hidden 17 frame]\u001b[0m\n",
      "File \u001b[0;32m/home/dev/untitled/untitled/layers.py:492\u001b[0m, in \u001b[0;36mDecoderLayer.__call__\u001b[0;34m(self, inputs, decoder_mask, deterministic, decode, max_decode_length)\u001b[0m\n\u001b[1;32m    484\u001b[0m layer_norm_output \u001b[39m=\u001b[39m LayerNorm(\n\u001b[1;32m    485\u001b[0m     dtype\u001b[39m=\u001b[39mconfig\u001b[39m.\u001b[39mdtype,\n\u001b[1;32m    486\u001b[0m     name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mpre_self_attention_layer_norm\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m    487\u001b[0m     kernel_axes\u001b[39m=\u001b[39m(\u001b[39m'\u001b[39m\u001b[39membed\u001b[39m\u001b[39m'\u001b[39m,)\n\u001b[1;32m    488\u001b[0m )(inputs)\n\u001b[1;32m    490\u001b[0m layer_norm_output \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mwith_logical_constraint(layer_norm_output, (\u001b[39m'\u001b[39m\u001b[39mactivation_batch\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mactivation_length\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mactivation_embed\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[0;32m--> 492\u001b[0m attention_output \u001b[39m=\u001b[39m MultiHeadDotProductAttention(\n\u001b[1;32m    493\u001b[0m     num_heads\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mnum_heads,\n\u001b[1;32m    494\u001b[0m     dtype\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mdtype,\n\u001b[1;32m    495\u001b[0m     head_dim\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mhead_dim,\n\u001b[1;32m    496\u001b[0m     dropout_rate\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mdropout_rate,\n\u001b[1;32m    497\u001b[0m     name\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mself_attention\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m    498\u001b[0m     config\u001b[39m=\u001b[39;49mconfig\n\u001b[1;32m    499\u001b[0m )(layer_norm_output, layer_norm_output, decoder_mask, decoder_bias, deterministic\u001b[39m=\u001b[39;49mdeterministic, decode\u001b[39m=\u001b[39;49mdecode)\n\u001b[1;32m    501\u001b[0m attention_output \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mwith_logical_constraint(attention_output, (\u001b[39m'\u001b[39m\u001b[39mactivation_batch\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mactivation_length\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mactivation_embed\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[1;32m    503\u001b[0m mlp_output \u001b[39m=\u001b[39m MLPBlock(\n\u001b[1;32m    504\u001b[0m     intermediate_dim\u001b[39m=\u001b[39mconfig\u001b[39m.\u001b[39mmlp_dim,\n\u001b[1;32m    505\u001b[0m     activations\u001b[39m=\u001b[39mconfig\u001b[39m.\u001b[39mmlp_activations,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    509\u001b[0m     config\u001b[39m=\u001b[39mconfig\n\u001b[1;32m    510\u001b[0m )(layer_norm_output, deterministic\u001b[39m=\u001b[39mdeterministic)\n",
      "    \u001b[0;31m[... skipping hidden 2 frame]\u001b[0m\n",
      "File \u001b[0;32m/home/dev/untitled/untitled/layers.py:189\u001b[0m, in \u001b[0;36mMultiHeadDotProductAttention.__call__\u001b[0;34m(self, inputs_q, inputs_kv, mask, bias, decode, deterministic)\u001b[0m\n\u001b[1;32m    186\u001b[0m     attention_bias \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    188\u001b[0m \u001b[39mif\u001b[39;00m bias \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m: \u001b[39m# add provided bias term(e.g. relative position embedding)\u001b[39;00m\n\u001b[0;32m--> 189\u001b[0m     attention_bias \u001b[39m=\u001b[39m combine_biases(attention_bias, bias)\n\u001b[1;32m    191\u001b[0m dropout_rng \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m deterministic \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout_rate \u001b[39m>\u001b[39m \u001b[39m0.\u001b[39m:\n",
      "\u001b[0;31mTypeError\u001b[0m: combine_biases() takes 0 positional arguments but 2 were given"
     ]
    }
   ],
   "source": [
    "# State\n",
    "state, state_mesh_annotations = utils.setup_initial_state(model, optimizer, hparam.config, init_rng, mesh, checkpoint_manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jax_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
